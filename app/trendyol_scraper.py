import httpx
import re
from typing import Dict, List
from bs4 import BeautifulSoup
import random

class TrendyolScraper:
    def __init__(self):
        self.base_url = "https://www.trendyol.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # FarklÄ± User-Agent'lar
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0'
        ]
    
    async def search_book_sales_data(self, book_title: str) -> Dict:
        """Kitap satÄ±ÅŸ verilerini ara"""
        try:
            print(f"ğŸ” Trendyol'da arama: {book_title}")
            
            # Kitap arama
            products = await self._search_books(book_title)
            if not products:
                print("âŒ ÃœrÃ¼n bulunamadÄ±")
                return self._get_default_data(book_title)
            
            # En iyi Ã¼rÃ¼nÃ¼ seÃ§
            best_product = self._select_best_product(products, book_title)
            if not best_product:
                print("âŒ Uygun Ã¼rÃ¼n bulunamadÄ±")
                return self._get_default_data(book_title)
            
            # ÃœrÃ¼n detaylarÄ±nÄ± al
            product_details = await self._get_product_details(best_product['url'])
            
            return {
                'product_name': best_product['title'],
                'product_url': best_product['url'],
                'current_price': best_product['price'],
                'sales_data': product_details,
                'source': 'trendyol_scraper'
            }
            
        except Exception as e:
            print(f"âŒ Arama hatasÄ±: {str(e)}")
            return self._get_default_data(book_title)
    
    async def _search_books(self, book_title: str) -> List[Dict]:
        """Kitap arama"""
        search_urls = [
            f"https://www.trendyol.com/sr?q={book_title.replace(' ', '+')}&qt=kitap",
            f"https://www.trendyol.com/sr?q={book_title.replace(' ', '+')}",
            f"https://www.trendyol.com/arama?q={book_title.replace(' ', '+')}"
        ]
        
        for url in search_urls:
            try:
                print(f"ğŸ” URL deneniyor: {url}")
                
                # FarklÄ± User-Agent'lar dene
                for user_agent in self.user_agents:
                    try:
                        headers = self.headers.copy()
                        headers['User-Agent'] = user_agent
                        
                        async with httpx.AsyncClient() as client:
                            response = await client.get(url, headers=headers, timeout=10.0)
                            
                            if response.status_code == 200:
                                soup = BeautifulSoup(response.content, 'html.parser')
                                products = self._parse_search_results(soup)
                                if products:
                                    print(f"âœ… {len(products)} Ã¼rÃ¼n bulundu")
                                    return products
                            elif response.status_code == 403:
                                print(f"âš ï¸ 403 hatasÄ±, farklÄ± User-Agent deneniyor...")
                                continue
                            else:
                                print(f"âš ï¸ {response.status_code} hatasÄ±")
                                
                    except Exception as e:
                        print(f"âš ï¸ User-Agent hatasÄ±: {str(e)}")
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ URL hatasÄ±: {str(e)}")
                continue
        
        print("âŒ TÃ¼m URL'ler baÅŸarÄ±sÄ±z")
        return []
    
    def _parse_search_results(self, soup: BeautifulSoup) -> List[Dict]:
        """Arama sonuÃ§larÄ±nÄ± parse et"""
        products = []
        
        try:
            # ÃœrÃ¼n kartlarÄ±nÄ± bul
            product_cards = soup.find_all('div', class_='p-card-wrppr')
            
            for card in product_cards[:10]:  # Ä°lk 10 Ã¼rÃ¼n
                try:
                    # BaÅŸlÄ±k
                    title_elem = card.find('span', class_='prdct-desc-cntnr-name')
                    if not title_elem:
                        continue
                    title = title_elem.get_text(strip=True)
                    
                    # Fiyat
                    price_elem = card.find('div', class_='prc-box-dscntd')
                    if not price_elem:
                        continue
                    price_text = price_elem.get_text(strip=True)
                    price = self._extract_price(price_text)
                    
                    # URL
                    link_elem = card.find('a')
                    if not link_elem:
                        continue
                    url = link_elem.get('href')
                    if url and not url.startswith('http'):
                        url = self.base_url + url
                    
                    products.append({
                        'title': title,
                        'price': price,
                        'url': url
                    })
                    
                except Exception as e:
                    continue
            
        except Exception as e:
            print(f"âŒ Parse hatasÄ±: {str(e)}")
        
        return products
    
    def _select_best_product(self, products: List[Dict], book_title: str) -> Dict:
        """En iyi Ã¼rÃ¼nÃ¼ seÃ§"""
        if not products:
            return None
        
        # Fiyata gÃ¶re sÄ±rala
        products.sort(key=lambda x: x.get('price', 0))
        
        # En ucuz Ã¼rÃ¼nÃ¼ dÃ¶ndÃ¼r
        return products[0]
    
    async def _get_product_details(self, product_url: str) -> Dict:
        """ÃœrÃ¼n detay sayfasÄ±ndan veri Ã§ek"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(product_url, headers=self.headers, timeout=10.0)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    return self._parse_product_details(soup)
                else:
                    print(f"âŒ ÃœrÃ¼n detay hatasÄ±: {response.status_code}")
                    return self._get_default_product_data()
                    
        except Exception as e:
            print(f"âŒ ÃœrÃ¼n detay hatasÄ±: {str(e)}")
            return self._get_default_product_data()
    
    def _parse_product_details(self, soup: BeautifulSoup) -> Dict:
        """ÃœrÃ¼n detaylarÄ±nÄ± parse et"""
        try:
            data = {
                'sales_count': 0,
                'rating_count': 0,
                'rating_score': 0.0,
                'review_count': 0,
                'popularity_score': 0.0
            }
            
            # DeÄŸerlendirme sayÄ±sÄ±
            rating_elem = soup.find('span', class_='ratingCount')
            if rating_elem:
                rating_text = rating_elem.get_text(strip=True)
                data['rating_count'] = self._extract_number(rating_text)
            
            # DeÄŸerlendirme puanÄ±
            score_elem = soup.find('span', class_='ratingScore')
            if score_elem:
                score_text = score_elem.get_text(strip=True)
                data['rating_score'] = self._extract_float(score_text)
            
            # Yorum sayÄ±sÄ±
            review_elem = soup.find('span', class_='reviewCount')
            if review_elem:
                review_text = review_elem.get_text(strip=True)
                data['review_count'] = self._extract_number(review_text)
            
            # SatÄ±ÅŸ gÃ¶stergeleri (varsa)
            sales_indicators = [
                'son 30 gÃ¼nde',
                'satÄ±ldÄ±',
                'kez satÄ±ldÄ±',
                'adet satÄ±ldÄ±'
            ]
            
            page_text = soup.get_text().lower()
            for indicator in sales_indicators:
                if indicator in page_text:
                    # SatÄ±ÅŸ sayÄ±sÄ±nÄ± bul
                    pattern = r'(\d+)\s*(?:kez|adet)?\s*satÄ±ldÄ±'
                    match = re.search(pattern, page_text)
                    if match:
                        data['sales_count'] = int(match.group(1))
                        break
            
            # PopÃ¼lerlik skoru hesapla
            data['popularity_score'] = self._calculate_popularity_score(data)
            
            return data
            
        except Exception as e:
            print(f"âŒ Detay parse hatasÄ±: {str(e)}")
            return self._get_default_product_data()
    
    def _calculate_popularity_score(self, data: Dict) -> float:
        """PopÃ¼lerlik skoru hesapla"""
        score = 0.0
        
        # DeÄŸerlendirme sayÄ±sÄ± etkisi
        if data['rating_count'] > 0:
            score += min(data['rating_count'] / 100, 1.0) * 0.4
        
        # DeÄŸerlendirme puanÄ± etkisi
        if data['rating_score'] > 0:
            score += (data['rating_score'] / 5.0) * 0.3
        
        # Yorum sayÄ±sÄ± etkisi
        if data['review_count'] > 0:
            score += min(data['review_count'] / 50, 1.0) * 0.2
        
        # SatÄ±ÅŸ sayÄ±sÄ± etkisi
        if data['sales_count'] > 0:
            score += min(data['sales_count'] / 100, 1.0) * 0.1
        
        return min(score, 1.0)
    
    def _extract_price(self, price_text: str) -> float:
        """Fiyat metninden sayÄ±sal deÄŸeri Ã§Ä±kar"""
        try:
            # SayÄ±larÄ± ve nokta/virgÃ¼lÃ¼ al
            price_match = re.search(r'[\d.,]+', price_text.replace(' ', ''))
            if price_match:
                price_str = price_match.group(0)
                # VirgÃ¼lÃ¼ noktaya Ã§evir
                price_str = price_str.replace(',', '.')
                return float(price_str)
        except:
            pass
        return 0.0
    
    def _extract_number(self, text: str) -> int:
        """Metinden sayÄ± Ã§Ä±kar"""
        try:
            match = re.search(r'\d+', text.replace(' ', ''))
            if match:
                return int(match.group(0))
        except:
            pass
        return 0
    
    def _extract_float(self, text: str) -> float:
        """Metinden ondalÄ±k sayÄ± Ã§Ä±kar"""
        try:
            match = re.search(r'[\d.,]+', text.replace(' ', ''))
            if match:
                price_str = match.group(0).replace(',', '.')
                return float(price_str)
        except:
            pass
        return 0.0
    
    def _get_default_data(self, book_title: str) -> Dict:
        """VarsayÄ±lan veri"""
        return {
            'product_name': book_title,
            'product_url': '',
            'current_price': 0,
            'sales_data': self._get_default_product_data(),
            'source': 'default'
        }
    
    def _get_default_product_data(self) -> Dict:
        """VarsayÄ±lan Ã¼rÃ¼n verisi"""
        return {
            'sales_count': 0,
            'rating_count': 0,
            'rating_score': 0.0,
            'review_count': 0,
            'popularity_score': 0.5
        } 